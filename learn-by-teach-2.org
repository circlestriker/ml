* 第一章回顾

练习

什么是正则化?

什么是超参数?

什么是验证集?

什么是交叉验证?



* 一个完整的机器学习项目
使用真实数据

** 项目概览

利用加州普查数据，建立一个加州房价模型

机器学习项目清单
*** 划定问题
第一个问题是商业目标是什么

第二个问题是现在的解决方案效果如何

*** 选择评估指标
均方根误差（RMSE）

平均绝对误差(MAE)

*** 核实假设
避免费力不讨好

** 获取数据

*** 创建工作空间
anaconda一般用于计算领域，普通的web等领域还是用virtualenv比较方便
用conda 多个环境切换比较方便。 现有工具支持好。

*** 下载数据

*** 快速查看数据结构

直方图获得感性认识

** 创建测试集
例如，你可以计算出每个实例ID的哈希值，只保留其最后一个字节，如果该值小于等于 51（约为 256 的 20%），就将其放入测试集。这样可以保证在多次运行中，测试集保持不变，即使更新了数据集。新的测试集会包含新实例中的 20%，但不会有之前位于训练集的实例。

id涉及到测试集的稳定性，即新实例加入时，新实例集的20%加入测试集，测试集原来的数据不变。//p53

需要保证新数据都放到现有数据的尾部，且没有行被删除。
如果做不到，则可以用最稳定的特征来创建唯一识别码。例如，一个区的维度和经度在几百万年之内是不变的，所以可以将两者结合成一个 ID

分层采样（stratified sampling）
假设某国有 3 个城镇：
A 镇有 100 万工人，
B 镇有 200 万工人，以及
C 镇有 300 万工人。

可以在整国人口中抽60大小的样本，这个可能导致较大偏差。可能60人都是A镇的。
分层采样: 分别在ABC抽10,20,30人。
为何不命名为: 均匀采样?

? 如果调查公司采用纯随机采样，会有 12% 的概率导致采样偏差

生成测试集是机器学习非常重要的一部分


# # np.random.seed()的作用

关于seed()函数用法：seed( ) 用于指定随机数生成时算法开始的整数值。 1.如果使用相同的seed( )值，则每次生成的随即数都相同； 2.如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同。 3.设置的seed()值仅一次有效

# ### 当我们设置相同的seed时，每次生成的随机数也相同，如果不设置seed，则每次生成的随机数都会不一样
# In[1]:
from numpy.random import rand
import numpy as np
# 不使用seed
a = rand(5)
print('第一次列表a：',a)
# In[2]:
a = rand(5)
print('第二次列表a：',a)
# In[3]:
# 使用seed
np.random.seed(3)
b = rand(5)
print('第一次列表b：',b)
# In[4]:
np.random.seed(3)
b = rand(5)
print('第二次列表b：',b)

** 数据探索和可视化、发现规律


中位数和平均数不同

drop函数默认删除行，列需要加axis = 1

估算器的关键词是fit:比如将缺失值用中位数估算填充。
转换器的关键词是transform: 转换器属于估算器的一种。能转换数据集的估算器。
预测器也是估算器的一种:能基于给定的数据集进行预测。


处理文本:
大部分机器学习算法更易于和数字打交道，需要将文本标签转为数字。
算法会以为2个相近数字更为相似一些。如果真实情况并非如此，可以用OneHotEncoder将整数分类值转为独热向量。
独热向量无相近数字，均是某一个元素是1其余为0的向量，避免了相似度误判。

标准化:平均值作为参照标准，故曰标准化。

*** 选择和训练模型
fit之后就可以得到模型了，就可以预测predict了

MSE: mean squared error
RMSE: root mean squared error

*** 交叉验证
产生背景: 决策树在整个训练集过拟合了，又不能动测试集，有个办法就是用部分训练集训练，剩余训练集验证。于是有了交叉验证。


housing.iloc[:5]

*** 网格搜索
?什么是网格搜索
网格搜索是一种通过遍历给定的参数组合(比如决策树的最大深度)来优化模型表现的方法。
参数组合形成的空间，类似网格，故名网格搜索。

给出一系列的最大深度的值，比如 {'max_depth': [1,2,3,4,5]}，希望选择最优最大深度。
如何评估哪个最大深度的模型是最优的呢? 其中一个经典的方法是K折交叉验证。

? 何时用gridsearch
需要优化模型时。
如直接用决策树得到的分数大约是92%，经过网格搜索优化以后，可以在测试集得到95.6%的准确率。

? 网格搜索会自动查找是否添加我们不确定的特征, 如何做到的?


# Label those above 5 as 5
housing["income_cat"].where(housing["income_cat"] < 5, 5.0, inplace=True)
#上面为什么是<5


*** 属性组合试验

scatter_matrix画出的图，对角线为什么是直方图?

相关矩阵：
>>> corr_matrix = housing.corr()
显然，卧室数/总房间数的比例越低，房价就越高。每户的房间数也比街区的总房间数的更有信息，很明显，房屋越大，房价就越高。
这一步的数据探索不必非常完备，此处的目的是有一个正确的开始，快速发现规律，以得到一个合理的原型

** 为机器学习算法准备数据

建立自己的函数库

*** 数据清洗

处理缺失值(total_bedrooms有缺失):
-去掉对应街区
-去掉整个属性
-用(0,平均值,中位数等)赋值

Scikit-Learn 提供了一个方便的类来处理缺失值：Imputer。
因为只有数值属性才能算出中位数，我们需要创建一份不包括文本属性ocean_proximity的数据副本.

Scikit-Learn 设计
- 接口一致性: 估计器、转换器、预测器。
- 可检验、可访问
- 类不可扩散。保持了简单
- 可组合
- 合理的默认值

*** 处理文本和类别属性

在原书中使用LabelEncoder转换器来转换文本特征列的方式是错误的，该转换器只能用来转换标签（正如其名）。在这里使用LabelEncoder没有出错的原因是该数据只有一列文本特征值，在有多个文本特征列的时候就会出错。应使用factorize()方法来进行操作：
housing_cat_encoded, housing_categories = housing_cat.factorize()
housing_cat_encoded[:10]

*** 自定义转换器

加一个超参数。数据准备步骤越自动化，可以自动化的操作组合就越多，越容易发现更好用的组合（并能节省大量时间）。


*** 特征缩放

**** 线性函数归一化
（许多人称其为归一化（normalization））很简单：值被转变、重新缩放，直到范围变成 0 到 1

MinMaxScaler

feature_range

**** 标准化
首先减去平均值（所以标准化值的平均值总是 0），然后除以方差，使得到的分布具有单位方差。

?假设一个街区的收入中位数由于某种错误变成了100，归一化会将其它范围是 0 到 15 的值变为 0-0.15，但是标准化不会受什么影响。

StandardScaler
