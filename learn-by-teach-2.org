* 第一章回顾

练习

什么是正则化?
//简化模型，降低过度拟合的风险。简单化是正确的法则，故名正则化。

什么是超参数?
//用于选择模型。 超出模型之外，故名超参数

超参数是预设的
超参数是指模型的结构性设计和训练方式，而模型的参数则是用于目标推演。
换个角度说的话，模型参数是小循环，每个epoch会调整模型参数，超参则在某个模型训练过程中不会被改动；而超参是大循环，当模型训练完成后，根据整个模型的评估，决定如何调整超参数，再开始小循环的模型训练。

什么是验证集?
//100条数据，80条用来训练，20条用来测试。
//如果80条里，拿出10条进行验证，选择最优超参数，这个分出的10条，就是验证集

什么是交叉验证?
//刚才的80条训练数据，有8组10份的数据，8*10。   交叉验证的组数是8，80条都还是训练数据，也参与了验证。就不存在浪费训练数据的情况了。


std = sqrt(var)
对于理想的正态分布，mean +/- std，可以涵盖 68%；mean +/- 2x std 可以涵盖 95% 左右的数据。
经常用平均值加减1-2倍的标准差来看主要数据的范围。

标准差和平均值是一个数据单位，方差是std^2的单位。

* 一个完整的机器学习项目
使用真实数据

** 项目概览

利用加州普查数据，建立一个加州房价模型

机器学习项目清单
*** 划定问题
第一个问题是商业目标是什么

第二个问题是现在的解决方案效果如何

*** 选择评估指标
均方根误差（RMSE）

平均绝对误差(MAE)

*** 核实假设
避免费力不讨好

** 获取数据

*** 创建工作空间
anaconda一般用于计算领域，普通的web等领域还是用virtualenv比较方便
用conda 多个环境切换比较方便。 现有工具支持好。

*** 下载数据

*** 快速查看数据结构

直方图获得感性认识

** 创建测试集
例如，你可以计算出每个实例ID的哈希值，只保留其最后一个字节，如果该值小于等于 51（约为 256 的 20%），就将其放入测试集。这样可以保证在多次运行中，测试集保持不变，即使更新了数据集。新的测试集会包含新实例中的 20%，但不会有之前位于训练集的实例。

id涉及到测试集的稳定性，即新实例加入时，新实例集的20%加入测试集，测试集原来的数据不变。//p53

需要保证新数据都放到现有数据的尾部，且没有行被删除。
如果做不到，则可以用最稳定的特征来创建唯一识别码。例如，一个区的维度和经度在几百万年之内是不变的，所以可以将两者结合成一个 ID

分层采样（stratified sampling）
假设某国有 3 个城镇：
A 镇有 100 万工人，
B 镇有 200 万工人，以及
C 镇有 300 万工人。

可以在整国人口中抽60大小的样本，这个可能导致较大偏差。可能60人都是A镇的。
分层采样: 分别在ABC抽10,20,30人。
为何不命名为: 均匀采样?
同分布抽样?

? 如果调查公司采用纯随机采样，会有 12% 的概率导致采样偏差
51.3% 女
48.7% 男

513
487

*** TODO ?? 纯随机，12%

88% 

生成测试集是机器学习非常重要的一部分


# # np.random.seed()的作用

关于seed()函数用法：seed( ) 用于指定随机数生成时算法开始的整数值。 1.如果使用相同的seed( )值，则每次生成的随即数都相同； 2.如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同。 3.设置的seed()值仅一次有效

# ### 当我们设置相同的seed时，每次生成的随机数也相同，如果不设置seed，则每次生成的随机数都会不一样
# In[1]:
from numpy.random import rand
import numpy as np
# 不使用seed
a = rand(5)
print('第一次列表a：',a)
# In[2]:
a = rand(5)
print('第二次列表a：',a)
# In[3]:
# 使用seed
np.random.seed(3)
b = rand(5)
print('第一次列表b：',b)
# In[4]:
np.random.seed(3)
b = rand(5)
print('第二次列表b：',b)

** 数据探索和可视化、发现规律

? P58 聚类算法检测主群体

中位数和平均数不同

drop函数默认删除行，列需要加axis = 1

估算器的关键词是fit:比如将缺失值用中位数估算填充。
转换器的关键词是transform: 转换器属于估算器的一种。能转换数据集的估算器。
预测器也是估算器的一种:能基于给定的数据集进行预测。

标准化:平均值作为参照标准，故曰标准化。

*** 独热编码
处理文本:
大部分机器学习算法更易于和数字打交道，需要将文本标签转为数字。
算法会以为2个相近数字更为相似一些。如果真实情况并非如此，可以用OneHotEncoder将整数分类值转为独热向量。
独热向量无相近数字，均是某一个元素是1其余为0的向量，避免了相似度误判。

**** 什么是独热编码？

独热码，在英文文献中称做 one-hot code, 直观来说就是有多少个状态就有多少比特，而且只有一个比特为1，其他全为0的一种码制。举例如下：      假如有三种颜色特征：红、黄、蓝。 在利用机器学习的算法时一般需要进行向量化或者数字化。那么你可能想令 红=1，黄=2，蓝=3. 那么这样其实实现了标签编码，即给不同类别以标签。然而这意味着机器可能会学习到“红<黄<蓝”，但这并不是我们的让机器学习的本意，只是想让机器区分它们，并无大小比较之意。所以这时标签编码是不够的，需要进一步转换。因为有三种颜色状态，所以就有3个比特。即红色：1 0 0 ，黄色: 0 1 0，蓝色：0 0 1 。如此一来每两个向量之间的距离都是根号2，在向量空间距离都相等，所以这样不会出现偏序性，基本不会影响基于向量空间度量算法的效果

**** 独热编码优缺点
优点：独热编码解决了分类器不好处理属性数据的问题，在一定程度上也起到了扩充特征的作用。它的值只有0和1，不同的类型存储在垂直的空间。
?扩充特征
缺点：当类别的数量很多时，特征空间会变得非常大。在这种情况下，一般可以用PCA来减少维度。而且one hot encoding+PCA这种组合在实际中也非常有用。

**** 何时用/不用独热编码?
用: 需要解决类别型数据的离散值问题时。
不用: 特征虽是离散，但不用one-hot编码就可以很合理计算距离时。比如基于树的算法。
Tree Model不太需要one-hot编码： 对于决策树来说，one-hot的本质是增加树的深度。

*** 选择和训练模型
fit之后就可以得到模型了，就可以预测predict了

MSE: mean squared error
RMSE: root mean squared error

*** 交叉验证
产生背景: 决策树在整个训练集过拟合了，又不能动测试集，有个办法就是用部分训练集训练，剩余训练集验证。于是有了交叉验证。


housing.iloc[:5]

*** 网格搜索
?什么是网格搜索
网格搜索是一种通过遍历给定的参数组合(比如决策树的最大深度)来优化模型表现的方法。
参数组合形成的空间，类似网格，故名网格搜索。

给出一系列的最大深度的值，比如 {'max_depth': [1,2,3,4,5]}，希望选择最优最大深度。
如何评估哪个最大深度的模型是最优的呢? 其中一个经典的方法是K折交叉验证。

? 何时用gridsearch
需要优化模型时。
如直接用决策树得到的分数大约是92%，经过网格搜索优化以后，可以在测试集得到95.6%的准确率。

? 网格搜索会自动查找是否添加我们不确定的特征, 如何做到的?


# Label those above 5 as 5
housing["income_cat"].where(housing["income_cat"] < 5, 5.0, inplace=True)
#上面为什么是<5


*** 属性组合试验

scatter_matrix画出的图，对角线为什么是直方图?

相关矩阵：
>>> corr_matrix = housing.corr()
显然，卧室数/总房间数的比例越低，房价就越高。每户的房间数也比街区的总房间数的更有信息，很明显，房屋越大，房价就越高。
这一步的数据探索不必非常完备，此处的目的是有一个正确的开始，快速发现规律，以得到一个合理的原型

** 为机器学习算法准备数据

建立自己的函数库

*** 数据清洗

处理缺失值(total_bedrooms有缺失):
-去掉对应街区
-去掉整个属性
-用(0,平均值,中位数等)赋值

Scikit-Learn 提供了一个方便的类来处理缺失值：Imputer。
因为只有数值属性才能算出中位数，我们需要创建一份不包括文本属性ocean_proximity的数据副本.

Scikit-Learn 设计
- 接口一致性: 估计器、转换器、预测器。
- 可检验、可访问
- 类不可扩散。保持了简单
- 可组合
- 合理的默认值

*** 处理文本和类别属性

在原书中使用LabelEncoder转换器来转换文本特征列的方式是错误的，该转换器只能用来转换标签（正如其名）。在这里使用LabelEncoder没有出错的原因是该数据只有一列文本特征值，在有多个文本特征列的时候就会出错。应使用factorize()方法来进行操作：
housing_cat_encoded, housing_categories = housing_cat.factorize()
housing_cat_encoded[:10]

*** 自定义转换器

加一个超参数。数据准备步骤越自动化，可以自动化的操作组合就越多，越容易发现更好用的组合（并能节省大量时间）。


*** 特征缩放

**** 线性函数归一化
（许多人称其为归一化（normalization））很简单：值被转变、重新缩放，直到范围变成 0 到 1

为什么需要归一化:
比如，特征A的取值范围是[-1000,1000]，特征B的取值范围是[-1,1].如果使用logistic回归，w1*x1+w2*x2，因为x1的取值太大了，所以x2基本起不了作用。所以，必须进行特征的归一化，每个特征都单独进行归一化。

MinMaxScaler

feature_range

什么情况下(不)需要归一化？
需要： 基于参数的模型或基于距离的模型，都是要进行特征的归一化。
不需要：基于树的方法是不需要进行特征的归一化，例如随机森林，bagging 和 boosting等

**** 标准化
首先减去平均值（所以标准化值的平均值总是 0），然后除以方差，使得到的分布具有单位方差。

?假设一个街区的收入中位数由于某种错误变成了100，归一化会将其它范围是 0 到 15 的值变为 0-0.15，但是标准化不会受什么影响。

StandardScaler

** 启动、监控、维护系统

模型会随着数据的演化而性能下降

评估系统输入数据的质量。
有时因为低质量的信号（比如失灵的传感器发送随机值，或另一个团队的输出停滞），系统的表现会逐渐变差，但可能需要一段时间，系统的表现才能下降到一定程度，触发警报。如果监测了系统的输入，你就可能尽量早的发现问题。对于线上学习系统，监测输入数据是非常重要的。


定期用新数据训练模型。

定期保存系统状态快照，好能方便地回滚到之前的工作状态。
